{
  "name": "prompt-eval",
  "version": "1.0.0",
  "description": "Evaluate outputs with custom metrics",
  "main": "dist/index.js",
  "bin": {
    "prompt-eval": "./dist/index.js"
  },
  "scripts": {
    "build": "tsc",
    "start": "node dist/index.js",
    "dev": "ts-node src/index.ts",
    "prepublishOnly": "npm run build"
  },
  "keywords": [
    "prompt",
    "evaluation",
    "metrics",
    "ai",
    "llm",
    "testing"
  ],
  "author": "",
  "license": "MIT",
  "dependencies": {
    "commander": "^11.1.0",
    "js-yaml": "^4.1.0",
    "chalk": "^4.1.2"
  },
  "devDependencies": {
    "@types/js-yaml": "^4.0.9",
    "@types/node": "^20.10.0",
    "typescript": "^5.3.0"
  },
  "engines": {
    "node": ">=16.0.0"
  }
}
